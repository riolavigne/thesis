\section{Proofs for Fine-Grained One-Way Functions}
\label{sec:fgowfAppendix}

\begin{theorem}
	If there exists a Plantable $T(n)$-\ACIH~problem where $G(n)$ is $\PFT{T(n)}$ and $\epsilon < 5/12$, then $T(n)$-FGOWFs exist.
	\label{thm:plantableOWF}
\end{theorem}
\begin{proof}
	Let $P$ be a Plantable $T(n)$-\ACIH~problem where $G(n) = T(n)^{1-\delta}$ for some constant $\delta>0$. So, the (randomized) algorithm $\Plant$ is $\PFT{T(n)}$ and takes an instance $I$ with no solutions and an implicit randomness $r$, outputting an instance $I'$ that has at least one solution --- we write this as $\Plant(I; r)$ when explicitly noting which randomness was used.
	
	Since when using our one-way function, we will be generating input instances with $\Generate$, we want to show that being able to invert $\Plant$ over the distribution from $\Generate$ is as hard, in a fine-grained sense, as solving the \ACIH~problem $P$. Let $\epsilon$ be the upper bound on the total variation distance between $\Generate$ and $D_0(P,n)$, and between $\Plant(D_0(P,n))$ and $D_1(P,n)$, as per definition \ref{def:plantable}. This means that $2\epsilon$ is an upper bound on the total variation distance between $\Plant \circ \Generate$ and $D_1(P,n)$.
	
	Now, let $\cA$ be a $\PFT{T(n)}$ algorithm that inverts $\Plant$ on inputs generated by $\Generate$ with probability $\gamma > \frac{1}{6(1 - 2\epsilon)}$. Since $\epsilon < 5/12$, $\frac{1}{6(1 - 2\epsilon)}$ is a constant greater than $0$, and therefore so is $\gamma$. We will show that this violates the assumption that $P$ is a $T(n)$-\ACIH~problem.
	
	We now construct a $\PFT{T(n)}$ algorithm $\cB$ that distinguishes between $I \sim D_0(P,n)$ and $I \sim D_1(P,n)$ with probability greater than $2/3$, solving $P$.
	\begin{itemize}
		\item Given $I$ from distribution $D$, $\cB$ gives $I$ to $\cA$.
		\item $\cA$ outputs $\hat I, r$.
		\item If $\Plant(\hat I; r) == I$, output $1$. Otherwise, output $0$.
	\end{itemize}
	
	First, note that if $I \sim D_0(P,n)$, then there cannot exist any randomness $r$ or instance $I$ such that $\Plant(\hat I; r)$ because $\Plant(\hat I; r)$ always introduces a solution, and is therefore never in the support of $D_0(P,n)$. So, $\Pr_{I \sim D}[\cB(I) = 0 | I \sim D_0(P,n)] = 1$.
	
	Now, we compute the probability that $\cB$ outputs $1$ when $I' \sim D_1(P,n)$. Let 
	
	\begin{align*}
	p_{generated} &=\Pr_{I \sim D_1(P,n)}[\Plant(\cA(I)) = I | I \sim \Plant \circ \Generate]\\
	p_{generatable} &=\Pr_{I \sim D_1(P,n)}[I \sim \Plant \circ \Generate] 
	\end{align*}
	
	
	We have that
	\begin{align*}
	\Pr_{I \sim D}[\cB(I) = 1 | I \sim D_1(P,n)] &= \Pr_{I \sim D_1(P,n)}[\Plant(\cA(I)) = I ]\\
	&\ge p_{generated} \cdot p_{generatable}\\
	&> \gamma \cdot (1 - 2\epsilon) \ge \frac{(1 - 2\epsilon)}{6(1 - 2\epsilon)} = \frac 1 6.
	\end{align*}
	
	Therefore, the probability that $\cB$ correctly categorizes instances $I$ from $P$ is
	\[ \Pr_{I \sim D}[\cB(I) = val(I)] = \frac 1 2 \Pr_{I \sim D}[\cB(I) = 0 | I \sim D_0(P,n)] + \frac 1 2 \Pr_{I \sim D}[\cB(I) = 1 | I \sim D_1(P,n)] > \frac 1 2 + \frac 1 6 = \frac 2 3. \]
	%TODO: easy peasy
	So, assuming $P$ is $T(n)$-\ACIH, no adversary has better than a constant chance less than 1 of being able to invert $\Plant(I; r)$ is a medium $T(n)$-FGOWF. By claim \ref{thm:medium-strong-owf}, this implies there exist strong $T(n)$-FGOWFs.
\end{proof}
