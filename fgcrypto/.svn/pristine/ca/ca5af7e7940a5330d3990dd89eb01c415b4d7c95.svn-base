\section{Average Case Assumptions and their Justifications}

We will describe our results in key exchanges and one way functions using generic properties needed for our constructions. However, for concreteness we will describe a few specific plausible average case conjectures that satisfy the needed properties. 

These average case conjectures are based on popular worst case assumptions. 

We build a variety of cryptographic primitives from hypotheses. We define classes of hypotheses under which our constructions hold and also define specific believable hypotheses that meet these conditions. We begin by defining the general classes, then we define the concrete hypotheses, finally we prove that the concrete hypotheses meet the conditions needed. 


\begin{definition}[General Distributions]
We are considering problems that are search problems. These problems can potentially have more than one solution/witness. We will limit our consideration to the distributions over instances with no solutions and instances with a unique solution/witness. 

For a given search problem, $P$, we will consider the uniform distribution over all instances that have no solutions/witnesses, we will call this distribution $D_{0}$.

For a give search problem, $P$, we will consider the uniform distribution over all instances that have one unique solution/witness, we will call this distribution $D_{1}$.
\end{definition}

\subsection{General Classes of Hypotheses}
We will define general properties needed in a problem and hypothesis for it to be usable for our fine-grained one way functions and our fine-grained key exchange. These classes will be \plantable, average case self reducible and splittable.

To be maximally general we present these definitions with some parameters. Plantable is capturing the property of it being efficient to create an instance with a solution from an instance with no solutions. Average case self reducible is capturing the property that a problem can be made into many smaller instances such that solving them solves the original efficiently. Finally, Splittable is capturing the property that one can generate from one average case instance two average case instances which have the same number of solutions as the original.

These are natural properties for problems and hypotheses to have. We will demonstrate that zero $k$-clique has these properties. 

\newcommand{\ACIH}{ACIH}
\begin{definition}[Average Case Indistinguishably Hard]
For a problem $P$, let the distribution $D$ be the distribution drawing with probability $1/2$ from $D_{0}$ and $1/2$ from $D_{1}$.

Let $val(I)=0$ if $I$ is from the support of $D_{0}$ and let  $val(I)=1$ if $I$ is from the support of $D_{1}$.

$P$ is Average Case Indistinguishably Hard in time $T(n)$ ($T(n)$-\ACIH) if 
$\forall$ $\PFT{T(n)}$ algorithms $A$
\[ \Pr_{I \sim D}[A(I) = val(I)] \le 2/3 \]
\end{definition}

\newcommand{\Plant}{\mathsf{Plant}}

\newcommand{\Generate}{\mathsf{Generate}}

\begin{definition}[Plantable]
	A $T(n)$-\ACIH~problem is plantable in time $G(n)$ with error $\epsilon$ if there exists a randomized algorithms $\Plant$ and $\Generate$ that runs in time $G(n)$ such that:
	\begin{itemize}
		\item the distribution of the instances returned by $\Generate(n)$ has total variation distance at most $\epsilon$ from $D_{0}$.
		\item when given any instance $I$, $\Plant(I)$ has \emph{at least} one solution,
		\item and if $I \sim D_{0}$, then $\Plant(I)$ has total variation distance at most $\epsilon$ from $D_{1}$.
	\end{itemize}  
\end{definition}

% We are using the solution searching version. So, when there are no solutions you can spit out garbage. We only care about the instance that has the solution 
%

Intuitively the self reduction returns a list of smaller instances. Something that breaks our key exchange will, intuitively, return the index of which instance has a solution. If the smaller instances are small enough we can brute force the returned index and check if the answer is correct. Given this, if we split the smaller instances into groups, we only need that the one group that has a solution looks average case. This gives us extra flexibility. This means we need the distributions to not produce false positives, but don't need all produced instances to look like average case instances. 


\begin{definition}[Average Case Self-reducible]
A $T(n)$-\ACIH problem $P$ is Average Case Self-reducible if given a list of $\ell(n)$ instances, $\mathbf I = I_1,I_2,\ldots,I_{\ell(n)}$ each of size $n$
where $i \getsr [\ell(n)]$, $I_i \sim D_{1}$ and for all $j \neq i$, $I_j \sim D_{0}$,
for all $\PFT{T(n)\ell(n)}$ algorithms $A$,
\[ \Pr_{\mathbf I}[A(\mathbf I) = i] \le 7/10. \]
\end{definition}

Intuitively a splittable problem has a process in the average case to go from one instance $I$ into a pair of average looking problems with the same number of solutions. We use this property in the proof that our crypto system is hard. We can be more general than this, allowing the generation of many pairs some of which may be wrong. 

\newcommand{\Split}{\mathsf{Split}}
\begin{definition}[Splittable]
	A $T(n)$-\ACIH problem is splittable with error $\epsilon$ if there exists a $\PFT{T(n)}$ algorithm $\Split$
	\begin{itemize}
		\item when given an instance of a problem $I \sim D_{0}$ produces two instances $I_1,I_2$ with total variation distance $\epsilon$ from $D_{0}^2$.
		\item when given an instance of a problem $I \sim D_{1}$ produces two instances $I_1,I_2$ with total variation distance $\epsilon$ from $D_{1}^2$.
	\end{itemize}
\end{definition}



\subsection {Concrete Hypothesis}

\paragraph{Problem Descriptions}
We will consider the average case $k$-sum problem and the average case zero $k$-clique problems. 

First we consider the $k$-sum problem and define an average case distribution for this problem. The worst case hypothesis of the polynomial time hardness of $3$-sum was introduced by Gajentaan and Overmars \cite{3sumIntroductionOrig,3sumIntroduction}. The first statement of a conjectured the average case hard $3$-sum distribution was by Seth Pettie \cite{avgCase3Sum}. We propose a different distribution. 
\begin{definition}
	An average case k-sum instance over range $R$ is an instance with $kn$ numbers in $k$ lists $L_1, \ldots, L_k$. These numbers are chosen uniformly at random from the range $[0,R-1]$. 
	
	A solution in a k-sum instance is a set of $k$ numbers $a_1 \in L_1$, \ldots, $a_k \in L_k$ such that the sum is zero mod $R$, $\sum_{i=1}^k a_i \equiv 0 \mod R$. 
\end{definition}

We will also define the uniform distributions over $k$-sum instances that have a certain number of solutions. 
\begin{definition}
	The distribution $D_{ksum}[R,n]$ is the uniform distribution over $k$-sum instances where there are exactly $i$ distinct solutions. 
	
		Let $D^{ksum}_{0}[R,n] = D_{ksum}[R,0,k]$  and $D^{ksum}_{1}[R,n] = D_{ksum}[R,1,k]$.
\end{definition}


We also consider the zero k-clique problem and define the average case assumption for the $k$-clique problem. The first statement of the worst case hardness for zero 3-clique (zero triangle) was by Vassilevska Williams and Williams \cite{3cliqueIntro}. The zero k-clique assumption has been used in many papers \cite{BackursT16, abboud2014consequences, sparseGraphsLVWW, treeEditDistance}

\begin{definition}
	An average case zero k-clique instance over range $R$ is an instance with $kn$ nodes in a $k$-partite graph with partitions $P_1, \ldots, P_k$. There are edges between a node  $v\in P_i$ and a node $u \in P_j$ if and only if $i \ne j$. Thus, every instance has $kn^2$ edges. Weights are assigned to each of these edges uniformly at random from the range $[0,R-1]$. 
	
	A solution in a zero k-clique instance is a set of $k$ nodes $v_1 \in V_1$, \ldots, $v_k \in V_k$ such that the sum of all the weights on the $\binom{k}{2}$ edges in the $k$ clique formed by $v_1,\ldots,v_k$ is congruent to zero mod $R$, $\sum_{i \in [1,k]}\sum_{j \in [1,k] \text{ and } j\ne i} weight(v_i,v_j) \equiv 0 \mod R$. A solution is also called a zero weighted $k$-clique, or a zero $k$-clique. 
\end{definition}

We will additionally define the distributions of these instances in which a certain number of solutions appear. 
\begin{definition}
	The distribution is $D_{zkc}[R,i,k]$ the uniform distribution over zero k-clique instances where there are exactly $i$ distinct zero k-cliques in the graph. 
	
	Let $D^{zkc}_{0}[R,n] = D_{zkc}[R,0,k]$  and $D^{zkc}_{1}[R,n] = D_{zkc}[R,1,k]$.
\end{definition}

\paragraph{Weak and Strong Hypotheses}

We have weak and strong variants of the hypotheses. We can make the strong assumption these average case problems take as long as their worst case variants are hypothesized to take. Or, we can make the significantly weaker assumption that these average case problems take super-linear time over their input size. 


\begin{definition}[\Weakksum]
	There exists some constant $c>2$ such that returning the solution (returning the $k$ indices of the numbers that sum to zero) from an instance drawn from $D^{zkc}_{1}[cn^k,n]$ with probability greater than $1/3$ takes $n^{1+\delta-o(1)}$ time for some $\delta>0$. 
\end{definition}


\begin{definition}[\Strongksum]
	There exists some large enough $c$ such that returning the solution  (returning the $k$ indicies of the numbers that sum to zero) the instance drawn from $D^{zkc}_{1}[n^{ck},n]$ with probability greater than $1/3$ takes $n^{\lceil k/2 \rceil-o(1)}$ time. 
\end{definition}

\begin{definition}[\Weakzkc]
	There exists some large enough $c$ such that returning a zero $k$-clique (returning the $k$ nodes involved in the clique) from an instance drawn from $D^{zkc}_{1}[cn^{k},n]$ with probability greater than $1/3$ takes $n^{2+\delta-o(1)}$ time for some $\delta>0$. 
\end{definition}


\begin{definition}[\Strongzkc  in range $R(n)$]
	There exists some large enough $c$ such that returning a zero $k$-clique (returning the $k$ nodes involved in the clique) from an instance drawn from $D^{zkc}_{1}[cR(n),n]$ with probability greater than $1/3$ takes $n^{k-o(1)}$ time. 
\end{definition}