\section{Fine-Grained One-Way Functions}\label{sec:fg-owfs}

In this section, we give a construction of fine-grained OWFs (FGOWF) based on plantable $T(n)$-\ACIH~problems. We first show that even though the probability of inversion may be constant (called `medium' fine-grained one-way), we can do some standard boosting in the same way weak OWFs can be transformed into strong OWFs in the traditional sense. Then, given such a plantable problem, we will prove that $\Plant$ is a medium $T(n)$-FGOWF. Then, from this medium FGOWF, we can compile a strong FGOWF using this boosting trick. Then, since \zkclique~ is plantable (see theorem \ref{thm:zkcPlantable}), this implies \zkclique~ yields fine-grained OWFs.

Finally, we discuss the possibility of fine-grained hardcore bits and pseudorandom generators. It turns out that the standard Goldreich-Levin approach to creating hardcore bits works in a similar fashion here, but requires some finessing; it will not work for \emph{all} fine-grained OWFs.

\subsection{Weak and Strong OWFs in the Fine-Grained Setting}

In traditional cryptography, we have notions of weak and strong OWFs. Weak OWFs can be inverted most of the time, but a polynomial-fraction of the time, they cannot be. These weak OWFs can be compiled into strong OWFs (showing that weak OWFs imply strong OWFs), where there is a negligible chance that the resulting strong OWF is invertable over the choice of inputs.

Here we will briefly discuss how a 'medium' $T(n)$-FGOWF can imply a 'strong' $T(n)$-FGOWF, where 'strong' refers to definition \ref{def:fg-owf}

\begin{definition}
	A function $f$ is a medium $T(n)$-FGOWF if there exists a sub-polynomial function $Q(n)$ such that for all $\PFT{T(n)}$ adversaries $\cA$,
	\[ \Pr_{x \getsr \{0,\}^n}[ \cA(f(x)) \in f\inv(f(x)) ] \le 1 - \frac 1 {Q(n)}. \]
\end{definition}

\begin{claim}\label{thm:medium-strong-owf}
	Medium $T(n)$-FGOWFs imply strong $T(n)$-FGOWFs.
\end{claim}
\begin{proof}
	%TODO: fix this proof!
	The structure of this proof will follow Yao's original argument augmenting weak OWFs to strong ones. Intuitively, we are able to use this argument because sub-polynomial functions compose well with each other.
	
	Let $f$ be a medium $T(n)$-FGOWF, where the probability any $\PFT{T(n)}$ adversary inverts it is $1 - \frac 1 {Q(n)}$. The basic idea will be to produce $f'$ that is just a concatenation of many $f$s, just as in the traditional cryptographic case.
	
	For any constant positive integer function $c(n)$, let $f'(x_1 || \dots || x_{c(n)}) = f(x_1)|| \dots ||f(x_{c(n)})$. We will show that for $c(n) = 2Q^2(n)$ (note that $c$ is subpolynomial), $f'$ is a $T(n)$-FGOWF.
	
	For sake of contradiction, let $\cA$ be a $\PFT{T(n)}$ such that there exists a subpolynomial function $p(n)$ where
	\[\Pr[\cA'(f'(x_1 || \dots || x_c)) \in f'^{-1}(f'(x_1 || \dots || x_c))] \le \prod_{i=1}^c\Pr[\cA(f'(x_i))] \ge \frac 1 {p(n)}.\]

	We will define a $\PFT{T(n)}$ function $\cA_0$ that makes single call to $\cA$: on input $y = f(x)$
	\begin{enumerate}
		\item Choose $i \getsr [c(n)]$.
		\item Let $y_i = y$
		\item For all $j \in [c(n)]$, $j \neq i$, $x_j \getsr \{0,1\}^n$ and $y_j \getsr f(x_j)$.
		\item Run $\cA$ on $(y_1, \dots, y_{c(n)})$ to get output $(x_1, \dots, x_{c(n)})$ if $\cA$ succeeds.
		\item If $\cA$ succeeded, output $x_i$.
	\end{enumerate}
	
	Because all operations in $\cA_0$ are either calling $\cA$ (once) or take time $O(n\cdot c(n))$\footnote{It does not make much sense for $T(n)$ to be sublinear for our contexts}, $\cA_0$ is a $\PFT{T(n)}$ algorithm. Now, we will let $\cB$ be an algorithm calling $\cA_0$ $d(n) = 4c(n)p(n)Q(n)$ times, returning a valid inversion of $f(x)$ if $\cA$ succeeded at least once.
	
	We will call $x \in \{0,1\}^n$ 'good' if $\cA_0$ inverts it with probability at least $\frac 1 {2c^2(n)p(n)}$; $x$ is 'bad' otherwise. Notice that if $x$ is good, then $\cB$, which runs $\cA$ many times, succeeds with high probability:
	\[ \Pr[\cB(f(x)) \mbox{ fails} | x\mbox{ is good}] \le (1 - \frac 1{2c^2(n)p(n)})^{d(n)} \sim e^{-2Q(n)} < \frac 1 {2Q(n)}. \]
	
	
	We will show that there are at least $2^n(1 - \frac{1}{2p(n)})$ good elements.
	
	
	\begin{claim}
		There are at least $2^n(1 - \frac{1}{2p(n)})$ good elements.
	\end{claim}
	\begin{proof}
		For a contradiction, assume there are at least $2^n(\frac{1}{2p(n)})$ bad elements. We will end up contradicting the inversion probability of $\cA$ (which is at least $1/p(n)$). For notation, let $\vec x = (x_1, \dots, x_{c(n)}) \in \{0,1\}^{n\cdot c(n)}$, and $\vec x$ will be chosen uniformly at random over the input space.
		\begin{align*}
		\Pr_{\vec x}[\cA(\vec y = f'(\vec x)) \mbox{succeeds}] &= \Pr[\cA(\vec y)\mbox{ succeeds} \land \exists \mbox{bad }x_i] + \Pr[\cA(\vec y)\mbox{ succeeds} \land \mbox{ all } x_i \mbox{ good}]
		\end{align*}
		Now, for all $j \in [c(n)]$,
		\begin{align*}
		\Pr_{\vec x}[\cA(\vec y) \mbox{ succeeds} \land x_j\mbox{ is bad}] &\le \Pr_{\vec x}[\cA(\vec y) \mbox{ succeeds} |  x_j\mbox{ is bad}]\\
		%\cdot \Pr_{x_j}[ x_j\mbox{ is bad}]\\
		&\le c(n) \Pr_{\vec x}[\cA_0(f(x_j))\mbox{ succeeds} | x_j\mbox{ is bad}]\\
		&\le \frac{c(n)}{2c^2(n)p(n)} = \frac{1}{2c(n)p(n)}
		\end{align*}
		So, if we just union bound over all $j$, we get
		\[ \Pr_{\vec x}[\cA(\vec y) \mbox{ succeeds} \land \mbox{some } x_i \mbox{ are bad}] \le \sum_{j = 1}^{c(n)} \Pr_{\vec x}[\cA_0(f(x_j))\mbox{ succeeds} \land x_j\mbox{ is bad}] \le \frac{1}{2p(n)}. \]
		And one more quick upper bound yields
		\begin{align*}
		\Pr[\cA(\vec y) \mbox{ succeeds} \land {all } x_i \mbox{ are good}] &\le \Pr_{\vec x}[\mbox{all $x_i$ good}]\\
		&< (1 - \frac{1}{2Q(n)})^{c(n)} \sim e^{-2Q(n)} < \frac{1}{2Q(n)}
		\end{align*}
		Finally, this yields the contradiction that
		\begin{align*}
		\Pr_{\vec x}[\cA(\vec y) \mbox{ succeeds}] < \frac{1}{Q(n)}.
		\end{align*}
	\end{proof}

	Now that we know there is a high probability that we hit a good $x$, we can finish the rest of this proof.
	\begin{align*}
	\Pr_{x}[\cB(f(x)) \mbox{ fails}] &= \Pr[\cB(f(x)) \mbox{ fails} | x \mbox{ is good}] \Pr_x[x \mbox{ is good}] + \Pr[\cB(f(x)) \mbox{ fails} | x \mbox{ is bad}] \Pr_x[x \mbox{ is bad}]\\
	&\le\Pr[\cB(f(x)) \mbox{ fails} | x \mbox{ is good}] \Pr_x[x \mbox{ is good}] + \Pr_x[x \mbox{ is bad}]
	&\le \frac{1}{2Q(n)}(1 - \frac 1 {2Q(n)}) + \frac{1}{2Q(n)} < \frac 1 {Q(n)}
	\end{align*}
	Thus, the chance that $\cB$ actually has of inverting $f$ is strictly greater than $1 - \frac 1 {Q(n)}$, contradicting the claim that $f$ was medium-hard with respect to $Q(n)$.
\end{proof}

\paragraph{Weaker Fine-Grained OWFs.} Now, because we are in the fine-grained setting, we can talk about gaps. There is a notion of weak-OWFs in cryptography where we can say if there exists \emph{any} polynomial such that we can invert with probability $1 - 1/\poly$, we can construct strong OWFs. We want a similar notion for fine-grained OWFs. Here we can't just choose any polynomial --- we have to choose a polynomial that respects the gap.

Formally, for an $T(n)$-FGOWF $f$ that has $\PFT{T(n)}$ adversaries inverting it with probability $1 - 1/P(n)$, we can get that a $\PFT{T(n)}$ adversary can invert $f'$ with probability $(1 - 1/P(n))^{c(n)}$. Now, as long as there exists $\delta'$ such that $T(n)^{1-\delta}P(n) = T(n)^{1-\delta'}$, there is still a gap ($\delta' < \delta$) even if we compute $f$ $P(n)$ times to evaluate $f'$. Therefore, we are able to get a strong fine-grained OWF from a weak one, as long as it's not \emph{too} weak.

\subsection{Building Fine-Grained OWFs from Plantable Problems}

One can generate fine-grained one way functions from plantable problems. The proof is shown in Section \ref{sec:fgowfAppendix} in Theorem \ref{thm:plantableOWF}. We state the theorem here as well. 

\begin{theorem}
	If there exists a Plantable $T(n)$-\ACIH~problem where $G(n)$ is $\PFT{T(n)}$ and $\epsilon < 5/12$, then $T(n)$-FGOWFs exist.
\end{theorem}

Note that $k$-SUM-$R$ and  Zero-$k$-Clique-$R$ are plantable with error less than $<5/12$ the when $R>6 n^k$ by Theorem \ref{thm:zkcPlantable} and Theorem \ref{thm:ksumPlantable}.

\subsection{Fine-Grained Hard-Core Bits and Pseudorandom Generators}
One way functions serve as the building block for a lot of symmetric encryption, and are (usually) implied by any other cryptographic primitive, from collision-resistant hash functions to symmetric-key encryption, to any flavor of public key encryption, and so on. The next step to building more cryptographic primitives with one-way functions is to see if we can use them to construct pseudorandom generators. While we do not yet have a construction of a fine-grained pseudorandom generator that can generate some sub-polynomial many pseudorandom bits\footnote{Note that due to the nature of being fine-grained, we cannot generate polynomially-many bits without additional assumptions}, we take the first steps, showing how to get hardcore bits.

\begin{definition}\label{def:fg-hcb}
	A function $b$ is a fine-grained hard-core (FGHC) predicate for a $T(n)$-FGOWF if for all $\PFT{T(n)}$ adversaries $\cA$,
	\[ \Pr_{x \getsr \{0,1\}^n}[ \cA(f(x)) = b(x) ] \le \frac 1 2 + \insig(n). \]
\end{definition}

%There is one main difference between our fine-grained definition of hardcore bits and the traditional cryptographic definition: we do not require an adversary guessing the hardcore bit to have a negligible advantage. Now, with the computational XOR lemma, we can boost a $T(n)$-FGOWF with a hardcore bit to a new $T(n)$-FGOWF with a hardcore bit guessable with advantage $1/Q(n)$ for your favorite sub-polynomial $Q$.

%Note that if the gap $\delta$ for the FGOWF, we can go even further, boosting to a $T(n)^{1+\delta/2}$-FGOWF with gap $\delta/2$ and advantage $\frac{1}{Q(n)n^{\delta/2}}$, which is insignificant. Of course, this digs into the gap, allowing an adversary more time to invert.

Recall that in traditional cryptography, any OWF implies the existence of another OWF with a hardcore bit with the Goldreich-Levin (GL) construction \cite{hardCoreBitsAndXorLemmaFromGL}. The bad news: the GL construction required a security reduction with $O(n)$ evaluations of the one-way function. Given how we define problems to be $T(n)$-\ACIH~hard, this security reduction would not be $\PFT{T(n)}$.
%This is fine if the gap $T(n)^\delta$ is bigger than $O(n)$, but we sometimes have smaller gaps than this to work with. So, we are proposing a GL-like construction that works for some FG OWFs (and we will see later that it works for all of our proposed FG OWF constructions).

\begin{theorem}[Fine-Grained Goldreich-Levin]
	Let $f$ be an $\fgowf{T(n)}$. acting on strings $(x, y)$, where $x = n$ and $y = Q(n)$ for some subpolynomial $Q$, and let $\cA$ be a $\PFT{T(n)}$ such that
	\[\Pr[\cA(f(x,y), y) \in f^{-1}(f(x,y))] \ge \sig(n).\]
	Then, the function $f':~(x,y,r) \mapsto f(x,y)||r$ where $|r| = |y|$ has the hardcore bit $y \cdot r$.
\end{theorem}
\begin{proof}	
	Here we just trace through the GL reduction and show that as long as $|y|$ is sub-polynomial, the reduction will go through.
	
	First, the size of $y$, $Q(n)$, cannot be any subpolynomial, it must be large enough so that it is as hard to guess $y$ as it is to invert $f$ (because guessing $y$ yields a significant chance of inverting $f$). If $f$ is $T(n)$-hard to invert, then the time it takes to randomly guess bits, $2^{Q(n)}$, must be at least $T(n)$. Since $T(n)$ is at least linear, we can assume $Q(n) \ge \log(n)$.
	
	For a contradiction, assume that a $\PFT{T(n)}$ adversary $\cA$ has a significant advantage $\epsilon$ in determining $r \cdot y$ when given $f(x,y), r$. We will show this implies $\cB$, a $\PFT{T(n)}$ algorithm using $\cA$, can invert $f$ with significant probability.
	
	$\cB$ behaves as follows with parameter $m = 2Q(n)/\epsilon$ on input $x' = f(x,y)$:
	\begin{itemize}
		\item For every $i \in [Q(n)]$:
		\begin{enumerate}
			\item Choose $\log(m)$ pairs $(b_1, r_1), \dots, (b_{\log(m)}, r_{\log(m)}) \getsr \{0,1\} \times \{0,1\}^{Q(n)}$.
			\item For every $I$ in the powerset of $[\log(m)]$, let $(b'_I, r'_I) = \sum_{i \in I}(b_i, r_i)$.
			\item Let $r'_I \gets e_i \xor r_I$.
			\item Let $g_I \gets b'_I \xor \cA(x'||r_I)$
			\item Let $y'_i = \mathsf{Majority}({g_I})$
		\end{enumerate}
		\item Output $y' = y'_1, \dots, y'_{Q(n)}$.
	\end{itemize}
	
	First, consider the set $S = \{ (x,y) | \Pr_r[\cA(f(x,y)||r) = r\cdot y] \ge \frac \epsilon 2 \}$. A quick calculation yields $|S| > \epsilon\cdot 2^{n-1}\epsilon$.
	
	So, assume that our input $(x,y) \in S$. Now, assume that every pair we chose in step 1 has the property $b_1 = r_1 \cdot y$ (we that we correctly guessed the bit in question). This event occurs with probability $1/m$.
	
	Next, notice that each pair of $r'_I,$ and $r'_{I'}$ are independent, and so the whole set is pairwise independent. So, if $(x, y)\in S$, $\cA$ will return the correct bit given $f(x,y)||r_I$ at least $\epsilon/2$-fraction of the time for independent $r$'s. Because of the pairwise independence, a Chebyshev bound yields $\cA$ will return the correct bit a majority of the time after the $m$ queries (so $\mathsf{Majority}(\{g_I\})$ outputs the correct bit $y_i$) with probability at least $1-\frac 1 {m(\epsilon/2)^2}$.
	
	Finally, we put all of these pieces together to get
	\begin{align*}
	\Pr[\cB(f(x,y)) = y] & \ge \Pr[\cB(f(x,y)) = y | (x,y)\in S ] \cdot \frac \epsilon 2\\
	&= \frac \epsilon 2 \left( 1 - \Pr[\exists i \mbox{ s.t. } y_i \neq y'_i | (x,y) \in S] \right)\\
	&\ge \frac \epsilon 2 \left(1 - Q(n)\Pr[y_i \neq y'_i | (x,y) \in S]\right)\\
	&\ge \frac \epsilon 2 \left(1 - Q(n)\Pr[y_i \neq y'_i | (x,y) \in S \land \mbox{guessed all $b_i$ correctly}]\cdot \frac 1 m\right)\\
	&\ge \frac \epsilon 2 \left(1 - \frac {Q(n)}{m} \cdot \frac{1}{m(\epsilon/2)^2} \right)\\
	&= \frac \epsilon 2 - \frac{4Q(n)}{m^2\epsilon}
	\end{align*}
	
	Recall we set $m = 2Q(n)/\epsilon$, and since $\epsilon$ is significant and $Q$ is subpolynomial, $m$ is also subpolynomial. Importantly, because $\cB$ runs in $O(Q(n) \cdot m T(n)^{1-\delta})$, $\cB$ is $\PFT{T(n)}$.
	
	Therefore, the probability that $\cB$ succeeds in finding $y_i$ (and hence inverting $f(x,y)$ with significant probability), with probability $\frac \epsilon 2 - \frac{4 Q(n)\epsilon}{4Q^2(n)} \ge  \frac \epsilon 2 - \frac{4\epsilon}{Q(n)}$. Recall that $Q(n)$ is at least linear in $n$, and so we can assume $Q(n) > 4$. This implies the probability $\cB$ succeeds is $\frac \epsilon 4$. 
	
	Because $\epsilon$ is significant, $\cB$ breaks the fine-grained one-wayness of $f$. This is a contradiction. Therefore, $\epsilon$ must be insignificant.
\end{proof}

\subsubsection{Hardcore bits from $k$-SUM and Zero $k$-Clique}
For both of these problems, planting a solution is exactly choosing some number of values ($k$ for $k$-SUM, and the edge weights of a $k$-clique for Zero $k$-Clique) and  changing one of them so that the values now give a solution.

\begin{corollary}
	Assuming either the Weak $k$-SUM hypothesis or weak Zero $k$-Clique hypothesis, there exist FGOWFs with fine-grained hardcore bits.
\end{corollary}
\begin{proof}
	See Corollary 
	\ref{cor:hardcorebitkclique} in Section \ref{sec:fgowfAppendix}.  
\end{proof}


%\xxx{Rio: To deal with at a later point. Maybe just some discussion.}
%\begin{claim}
%	Suppose $f$ is a medium or strong $\fgowf{T(n)}$ acting on $(x,y)$ where $x = n$ and $y = Q(n)$ for some subpolynomial $Q$, and let $b$ be a predicate on $(x,y)$ such that for all $\PFT{T(n)}$ adversaries $\cA$, $\Pr[\cA(f(x,y)) = b(x,y)] \le \frac 1 2 + \frac 1 {Q'(n)}$ for any subpolynomial $Q'$, then there exists a strong $\fgowf{T(n)}$ $f'$ with a strong hardcore bit $b'$.
%\end{claim}
%\begin{proof}
	%	This is just an application of the computational XOR lemma \cite{Vaz87} in combination with the techniques from claim \ref{thm:medium-strong-owf}.
	%	
	%	Recall the technique from claim \ref{thm:medium-strong-owf}: $f'$ consisted of concatenating $f$ together many times. How many times depends on whether or not $f'$ is easy to invert. If $\Pr[\cA(f(x)) \in f\inv(f(x))] = 1 - \frac 1 {\hat Q(n)}$ (so $f$ could be medium or strong since in both cases $\hat Q$ is sub-polynomial), then let $Q^*(n) = \max(Q'(n), \hat Q(n)) \cdot \log^2(n)$. Let $f' = f || \dots || f$, concatenated $Q^*(n)$ times. Then, $f'$ is definitely now a strong $\fgowf{T(n)}$, and also will have the following hardcore bit $b'$:
	%	\[b'((x_1, y_1) \dots, (x_{Q^*(n)}, y_{Q^*(n)})) = b(y_1) \xor \dots \xor b(y_{Q^*(n)}).\]
	%	
	%	Any $\PFT{T(n)}$ algorithm $\cA$ will be able to distinguish the vector $(b(y_1), \dots, b(y_{Q^*(n)})$
	%	\xxx{Rio: I'm having a very tough time figuring this out for whatever reason.}
	%TODO: figure this out
%\end{proof}
%%
%\paragraph{A note on fine-grained pseudorandom generators.}
%\xxx{Rio: I'm still looking into this. It's complicated...}
%TODO: constructions from GL and hc bits

%TODO: Hill construction? What about https://people.seas.harvard.edu/~salil/research/OWFtoPRG-stoc10.pdf

%\begin{definition}
%	A function $f$ is a nearly-weak $k,k'$-FGOWF if there exists a function $Q(n) \le O(n^{k-k'-\delta})$ for a constant $\delta > 0$ such that for all $\PFT{n^k}$ adversaries $\cA$,
%	\[ \Pr_{x \getsr \{0,\}^n}[ \cA(f(x)) \in f\inv(f(x)) ] \le 1 - \frac 1 {Q(n)}. \]
%\end{definition}
%
%\begin{claim}
%	Nearly-weak $k,k'$-FGOWFs imply strong $k$-FGOWFs.
%\end{claim}
%\begin{proof}
%	%TODO: it's gonna look like the previous proof
%\end{proof}
%
%%\remove{
%\xxx{There are some problems with these definitions. Need to work out where $\delta'$ comes in etc.}
%
%Just like in the usual cryptographic setting we have weak and strong OWFs (and weak OWFs imply strong OWFs), we have our own fine-grained version of weak and strong OWFs -- one will imply the other. There will be two versions: a `gap preserving' one-way function we will call a medium OWF, and an $\epsilon$-weak OWF.
%
%%TODO: there are some problems with these definitions...
%
%\paragraph{Definitions } 
%These functions will define the $\epsilon(n,\delta')$ to be different functions. In our first definition $\epsilon$ won't even depend on $\delta'$. It asks that the adversary have a sub-polynomial error in $n$.
%
%\begin{definition}[$d$-medium one-way functions]
%	A function $f: \{0,1\}^n \to \{0,1\}^*$ is $d$-medium one-way if $f(x)$ can be computed in $O(t(n))$ time and for all adversaries $\cA$ taking $O(t(n)^{g-\delta'})$ time for some $\delta'>0$, there exists a sub-polynomial function $
%	\epsilon(n)$ such that,
%	\[ \Pr_{x \gets \{0,1\}^n}\left[ \cA(f(x)) \in f\inv(x) \right] \le 1 - \frac 1 {\epsilon(n)} \]
%	%TODO: where does \delta' factor into this definition?
%	%%Andrea: I don't think it does. I think that we beleive that we can construct functions where, when \delta'>0 for any delta, the success is thus bounded. 
%\end{definition}
%
%In the above definition we force the adversary to err quite a bit. What about adversaries that err only $\frac{1}{\text{poly}(n)}$? Well, given that computing $f(n)$ takes $t(n)$ time and inverting $f(n)$ takes $t(n)^g$ time if the adversary errs, for example, $\frac{1}{t(n)^{g+1}}$ of the time, we could not detect this in $t(n)^g$ time. 
%
%But, the difference between inverting and solving gives us some space to work with, and in that space we can have certain amounts of error. 
%
%\begin{definition}
%	A function $f: \{0,1\}^n \to \{0,1\}^*$ is $(d,\epsilon)$-weak one-way if $f(x)$ can be computed in $O(t(n))$ time and for all adversaries $\cA$ taking $O(t(n)^{d-\delta'})$ time, there exists a function $g(n) = o(t(n)^{d-1-\epsilon})$ such that
%	\[ \Pr_{x \gets \{0,1\}^n}\left[ \cA(f(x)) \in f\inv(x) \right] \le 1 - \frac 1 {g(n)} \]
%\end{definition}
%
%\paragraph{Implications } 
%\begin{theorem}
%	The existence of a $d$-medium one-way function, $f$, implies the  existence of a $(d, n^{-c})$-one-way function, $f'$, for all constants $c$.
%\end{theorem}
%\begin{proof}
%	Let the probability of correct inversion of $f$ be upper bounded by $1-\frac 1 {g(n)}$. 
%	
%	We can draw $2cg(n)\lg(n)$  independent samples $x_1, \ldots , x_{2cg(n)\lg(n)}$ from $\{0,1\}^n$. Now, our new one way function is $f'(x_1|x_2| \ldots |x_{2cg(n)\lg(n)}) = f(x_1)||f(x_2)||\ldots||f(x_{2cg(n)\lg(n)})$. Correctly inverting the function $f'$ requires inverting $2cg(n)\lg(n)$ samples. The probability of correct inversion of this new function will be 
%	$(1-\frac 1 {g(n)})^{2g(n)\cdot c\lg(n)} < $
%	
%\end{proof}
%
%\begin{theorem}
%	The existence of a $(d,\epsilon)$-weak one-way function implies the  existence of a $(d/(d-\epsilon), n^{-c})$-one-way function for all constants $c$.
%\end{theorem}
%\begin{proof}
%	
%	\xxx{We build this proof by doing many repetitions of the medium one way functions. Repeating the function $cg(n)\lg(n)$ times achieves this while preserving the polynomial gap.}
%\end{proof}

%\xxx{Rio: removed explicit discussion about explicit $k$-SUM construction}
%\subsection{One Way Functions}

%\begin{theorem}
%If an problem is hypothesized to take  $\tilde{\Omega}(t(n)^{1+\delta})$ time for some $\delta>0$ time to find a solution with probability $\geq 1/3$  and is plantable in $t(n)$ time with error $< 2/3$ then a fine grained one way function exists. 
%\end{theorem}
%\begin{proof}
%	\xxx{TODO: but you know, its not so hard to prove this}
%\end{proof}

%Given $I,(a,b,c)$ and, $(w_{a,b}, w_{b,c})$ let $I'$ be an instance of $I$ with three edge weights changed. Specifically, set $w(e_{a,b})= w_{a,b}$, $w(e_{b,c})= w_{b,c}$ and, $w(e_{c,a})= -w_{a,b}-w_{b,c}$.
%
%\begin{definition}
%Let $I$ be an instance of $0$ k-clique
%Let $f_{kClique}$ be the function 
%$$f_{kClique}(I,(a,b,c),(w_{a,b}, w_{b,c})) =
%\begin{cases}
%\emptyset , & \text{if }e(a,b), e(b,c),\text{or } e(c,a) \text{ are involved in a }0 \text{-triangle in I} \\
%\emptyset , & \text{if }e(a,b), e(b,c),\text{or } e(c,a) \text{ are involved in }> \text{1  }0 \text{-triangles in I'} \\
%I', & \text{else}
%\end{cases}
%$$
%\end{definition}
%
%\xxx{TODO: can we get away with not checking for the null characters? It will still be hard over the distribution when the inputs are average case 0 solutions. Then computing $f$ will be $O(n^2)$ this doesn't matter unless $k>4$.}
%
%\begin{theorem}
%The function $f_{kClique}$ is a fine-grained one way function over the distribution of inputs drawn uniformly from $k$-Clique instances with $0$ solutions given the average case $0$-k Clique assumption. 
%\label{thm:kcliqueOWF}
%\end{theorem}
%\begin{proof}
%Computing $f_{kClique}$ takes $n^{k-2}$ time when the instance $I$ has $n$ nodes. 
%
%Let $D_I$ be the uniform distribution over $0$-k clique instances with $0$ solutions. \\
%Let $D_{a,b,c)}$ be the uniform distribution of triples with each value chosen uniformly from $[1,n]$.\\
%Let $D_{w}$ be the distribution from Lemma \ref{lem:kcliquePlant} that generates average case solutions. \\
%Let $D_{in}$ be the distribution made by sampling $I$ from $D_I$, $(a,b,c)$ from $D_{(a,b,c)}$ and $(w_{a,b},\ldots)$ from $D_{w}$.
%
%Let the Adversary have a $\epsilon$ probability of inverting the function when the input to the function is chosen from $D_{in}$.
%
%We will then use the adversary to distinguish a random $0$ solution instance from a $1$ solution instance. If we are given an instance $\hat{I}$ then we give the adversary this instance and ask for an inversion. 
%
%If the instance has $0$ solutions the adversary will be unable to invert (no $(a,b,c)$ triple will form a $0$-triangle). If the instance has $1$ solution, this is by Lemma \ref{lem:kcliquePlant} going to be the same distribution as applying the function to the distribution from $D_{in}$. 
%
%Thus, the Adversary will invert the function and find the $0$-k clique an $\epsilon$ fraction of the time. If the Adversary fails we will guess $0$ solutions, if the Adversary succeeds we will guess $1$ solution. 
%
%Given that  $\hat{I}$ has a $1/2$ chance of being a $0$ input then we guess correctly $1/2+\epsilon$ of the time. 
%
%Thus, the Adversary can not invert the function correctly with probability $\geq 1/3$.
%\end{proof}