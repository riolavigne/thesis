\section{Fine-Grained One-Way Functions}\label{sec:fg-owfs}

In this section, we give a construction of fine-grained OWFs (FGOWF) based on plantable $T(n)$-\ACIH~problems. We first show that even though the probability of inversion may be constant (called `medium' fine-grained one-way), we can do some standard boosting in the same way weak OWFs can be transformed into strong OWFs in the traditional sense. Then, given such a plantable problem, we will prove that $\Plant$ is a medium $T(n)$-FGOWF. Then, from this medium FGOWF, we can compile a strong FGOWF using this boosting trick. Then, since \zkclique is plantable (see theorem \ref{thm:zkcPlantable}), this implies \zkclique yields fine-grained OWFs.

Finally, we discuss the possibility of fine-grained hardcore bits and pseudorandom generators. It turns out that the standard Goldreich-Levin approach to creating hardcore bits works in a similar fashion here, but requires some finessing; it will not work for \emph{all} fine-grained OWFs.

\subsection{Weak and Strong OWFs in the Fine-Grained Setting}

In traditional cryptography, we have notions of weak and strong OWFs. Weak OWFs can be inverted most of the time, but a polynomial-fraction of the time, they cannot be. These weak OWFs can be compiled into strong OWFs (showing that weak OWFs imply strong OWFs), where there is a negligible chance that the resulting strong OWF is invertable over the choice of inputs.

Here we will briefly discuss how a 'medium' $T(n)$-FGOWF can imply a 'strong' $T(n)$-FGOWF, where 'strong' refers to definition \ref{def:fg-owf}

\begin{definition}
	A function $f$ is a medium $T(n)$-FGOWF if there exists a sub-polynomial function $Q(n)$ such that for all $\PFT{T(n)}$ adversaries $\cA$,
	\[ \Pr_{x \getsr \{0,\}^n}[ \cA(f(x)) \in f\inv(f(x)) ] \le 1 - \frac 1 {Q(n)}. \]
\end{definition}

\begin{claim}\label{thm:medium-strong-owf}
	Medium $T(n)$-FGOWFs imply strong $T(n)$-FGOWFs.
\end{claim}
\begin{proof}
	Let $f$ be a medium $T(n)$-FGOWF, where the probability any $\PFT{T(n)}$ adversary inverts it is $1 - \frac 1 {Q(n)}$. The basic idea will be to produce $f'$ that is just a concatenation of many $f$s, just as in the traditional cryptographic case.
	
	Let $\epsilon = 1 - 1/Q(n)$ be the probability of an adversary's success in inverting $f$. For any constant positive integer function $c(n)$, let $f'(x_1 || \dots || x_{c(n)}) = f(x_1)|| \dots ||f(x_{c(n)})$. Now, for any $\PFT{c(n) \cdot T(n)}$ adversary $\cA'$, there exists a $\PFT{T(n)}$ adversary $\cA$ such that
	\[\Pr[\cA'(f'(x_1 || \dots || x_c)) \in f'^{-1}(f'(x_1 || \dots || x_c))] \le \prod_{i=1}^c\Pr[\cA(f'(x_i))] = \epsilon^c.\]
	Now, if $c$ is subpolynomial, then $\PFT{c(n) \cdot T(n)} = \PFT{T(n)}$, since we ignore sub-polynomial factors.
	
	So, we let $c(n) = Q(n) \cdot \log^2(n)$, which is still subpolynomial. Then, for any $\PFT{T(n)}$ adversary $\cA'$, 
	\[\Pr[\cA'(f'(x_1 || \dots || x_c)) \in f'^{-1}(f'(x_1 || \dots || x_c))] \le (1 - \frac 1 {Q(n)})^{Q(n)\log^2(n)}\]
	\[ (1 - \frac 1 {Q(n)})^{Q(n)\log^2(n)} \sim \frac 1 {e^{\log^2(n)}} = \frac{1}{n^{\log n}} = \insig(n).\]
\end{proof}

\paragraph{Weaker Fine-Grained OWFs.} Now, because we are in the fine-grained setting, we can talk about gaps. There is a notion of weak-OWFs in cryptography where we can say if there exists \emph{any} polynomial such that we can invert with probability $1 - 1/\poly$, we can construct strong OWFs. We want a similar notion for fine-grained OWFs. Here we can't just choose any polynomial --- we have to choose a polynomial that respects the gap.

Formally, for an $T(n)$-FGOWF $f$ that has $\PFT{T(n)}$ adversaries inverting it with probability $1 - 1/P(n)$, we can get that a $\PFT{T(n)}$ adversary can invert $f'$ with probability $(1 - 1/P(n))^{c(n)}$. Now, as long as there exists $\delta'$ such that $T(n)^{1-\delta}P(n) = T(n)^{1-\delta'}$, there is still a gap ($\delta' < \delta$) even if we compute $f$ $P(n)$ times to evaluate $f'$. Therefore, we are able to get a strong fine-grained OWF from a weak one, as long as it's not \emph{too} weak.

\subsection{Building Fine-Grained OWFs from Plantable Problems}

One can generate fine-grained one way functions from plantable problems. The proof is shown in Section \ref{sec:fgowfAppendix} in Theorem \ref{thm:plantableOWF}. We state the theorem here as well. 

\begin{theorem}
	If there exists a Plantable $T(n)$-\ACIH~problem where $G(n)$ is $\PFT{T(n)}$ and $\epsilon < 5/12$, then $T(n)$-FGOWFs exist.
\end{theorem}

\subsection{Fine-Grained Hard-Core Bits and Pseudorandom Generators}
One way functions serve as the building block for a lot of symmetric encryption, and are (usually) implied by any other cryptographic primitive, from collision-resistant hash functions to symmetric-key encryption, to any flavor of public key encryption, and so on. The next step to building more cryptographic primitives with one-way functions is to see if we can use them to construct pseudorandom generators. While we do not yet have a construction of a fine-grained pseudorandom generator that can generate some sub-polynomial many pseudorandom bits\footnote{Note that due to the nature of being fine-grained, we cannot generate polynomially-many bits without additional assumptions}, we take the first steps, showing how to get hardcore bits.

\begin{definition}\label{def:fg-hcb}
	A function $b$ is a fine-grained hard-core (FGHC) predicate for a $T(n)$-FGOWF if for all $\PFT{T(n)}$ adversaries $\cA$,
	\[ \Pr_{x \getsr \{0,1\}^n}[ \cA(f(x)) = b(x) ] \le \frac 1 2 + \insig(n). \]
\end{definition}

%There is one main difference between our fine-grained definition of hardcore bits and the traditional cryptographic definition: we do not require an adversary guessing the hardcore bit to have a negligible advantage. Now, with the computational XOR lemma, we can boost a $T(n)$-FGOWF with a hardcore bit to a new $T(n)$-FGOWF with a hardcore bit guessable with advantage $1/Q(n)$ for your favorite sub-polynomial $Q$.

%Note that if the gap $\delta$ for the FGOWF, we can go even further, boosting to a $T(n)^{1+\delta/2}$-FGOWF with gap $\delta/2$ and advantage $\frac{1}{Q(n)n^{\delta/2}}$, which is insignificant. Of course, this digs into the gap, allowing an adversary more time to invert.

Recall that in traditional cryptography, any OWF implies the existance of another OWF with a hardcore bit with the Goldreich-Levin (GL) construction \cite{hardCoreBitsAndXorLemmaFromGL}. The bad news: the GL construction required a security reduction with $O(n)$ evaluations of the one-way function. Given how we define problems to be $T(n)$-\ACIH~hard, this security reduction would not be $\PFT{T(n)}$.
%This is fine if the gap $T(n)^\delta$ is bigger than $O(n)$, but we sometimes have smaller gaps than this to work with. So, we are proposing a GL-like construction that works for some FG OWFs (and we will see later that it works for all of our proposed FG OWF constructions).

\begin{theorem}[Fine-Grained Goldreich-Levin]
	Let $f$ be an $\fgowf{T(n)}$. acting on strings $(x, y)$, where $x = n$ and $y = Q(n)$ for some subpolynomial $Q$, and let $\cA$ be a $\PFT{T(n)}$ such that
	\[\Pr[\cA(f(x,y), y) \in f^{-1}(f(x,y))] \ge \sig(n).\]
	Then, the function $f':~(x,y,r) \mapsto f(x,y)||r$ where $|r| = |y|$ has the hardcore bit $y \cdot r$.
\end{theorem}
\begin{proof}	
	Here we just trace through the GL reduction and show that as long as $|y|$ is sub-polynomial, the reduction will go through.
	
	First, the size of $y$, $Q(n)$, cannot be any subpolynomial, it must be large enough so that it is as hard to guess $y$ as it is to invert $f$ (because guessing $y$ yields a significant chance of inverting $f$). If $f$ is $T(n)$-hard to invert, then the time it takes to randomly guess bits, $2^{Q(n)}$, must be at least $T(n)$. Since $T(n)$ is at least linear, we can assume $Q(n) \ge \log(n)$.
	
	For a contradiction, assume that a $\PFT{T(n)}$ adversary $\cA$ has a significant advantage $\epsilon$ in determining $r \cdot y$ when given $f(x,y), r$. We will show this implies $\cB$, a $\PFT{T(n)}$ algorithm using $\cA$, can invert $f$ with significant probability.
	
	$\cB$ behaves as follows with parameter $m = 2Q(n)/\epsilon$ on input $x' = f(x,y)$:
	\begin{itemize}
		\item For every $i \in [Q(n)]$:
		\begin{enumerate}
			\item Choose $\log(m)$ pairs $(b_1, r_1), \dots, (b_{\log(m)}, r_{\log(m)}) \getsr \{0,1\} \times \{0,1\}^{Q(n)}$.
			\item For every $I$ in the powerset of $[\log(m)]$, let $(b'_I, r'_I) = \sum_{i \in I}(b_i, r_i)$.
			\item Let $r'_I \gets e_i \xor r_I$.
			\item Let $g_I \gets b'_I \xor \cA(x'||r_I)$
			\item Let $y'_i = \mathsf{Majority}({g_I})$
		\end{enumerate}
		\item Output $y' = y'_1, \dots, y'_{Q(n)}$.
	\end{itemize}
	
	First, consider the set $S = \{ (x,y) | \Pr_r[\cA(f(x,y)||r) = r\cdot y] \ge \frac \epsilon 2 \}$. A quick calculation yields $|S| > \epsilon\cdot 2^{n-1}\epsilon$.
	
	So, assume that our input $(x,y) \in S$. Now, assume that every pair we chose in step 1 has the property $b_1 = r_1 \cdot y$ (we that we correctly guessed the bit in question). This event occurs with probability $1/m$.
	
	Next, notice that each pair of $r'_I,$ and $r'_{I'}$ are independent, and so the whole set is pairwise independent. So, if $(x, y)\in S$, $\cA$ will return the correct bit given $f(x,y)||r_I$ at least $\epsilon/2$-fraction of the time for independent $r$'s. Because of the pairwise independence, a Chebyshev bound yields $\cA$ will return the correct bit a majority of the time after the $m$ queries (so $\mathsf{Majority}(\{g_I\})$ outputs the correct bit $y_i$) with probability at least $1-\frac 1 {m(\epsilon/2)^2}$.
	
	Finally, we put all of these pieces together to get
	\begin{align*}
	\Pr[\cB(f(x,y)) = y] & \ge \Pr[\cB(f(x,y)) = y | (x,y)\in S ] \cdot \frac \epsilon 2\\
	&= \frac \epsilon 2 \left( 1 - \Pr[\exists i \mbox{ s.t. } y_i \neq y'_i | (x,y) \in S] \right)\\
	&\ge \frac \epsilon 2 \left(1 - Q(n)\Pr[y_i \neq y'_i | (x,y) \in S]\right)\\
	&\ge \frac \epsilon 2 \left(1 - Q(n)\Pr[y_i \neq y'_i | (x,y) \in S \land \mbox{guessed all $b_i$ correctly}]\cdot \frac 1 m\right)\\
	&\ge \frac \epsilon 2 \left(1 - \frac {Q(n)}{m} \cdot \frac{1}{m(\epsilon/2)^2} \right)\\
	&= \frac \epsilon 2 - \frac{4Q(n)}{m^2\epsilon}
	\end{align*}
	
	Recall we set $m = 2Q(n)/\epsilon$, and since $\epsilon$ is significant and $Q$ is subpolynomial, $m$ is also subpolynomial. Importantly, because $\cB$ runs in $O(Q(n) \cdot m T(n)^{1-\delta})$, $\cB$ is $\PFT{T(n)}$.
	
	Therefore, the probability that $\cB$ succeeds in finding $y_i$ (and hence inverting $f(x,y)$ with significant probability), with probability $\frac \epsilon 2 - \frac{4 Q(n)\epsilon}{4Q^2(n)} \ge  \frac \epsilon 2 - \frac{4\epsilon}{Q(n)}$. Recall that $Q(n)$ is at least linear in $n$, and so we can assume $Q(n) > 4$. This implies the probability $\cB$ succeeds is $\frac \epsilon 4$. 
	
	Because $\epsilon$ is significant, $\cB$ breaks the fine-grained one-wayness of $f$. This is a contradiction. Therefore, $\epsilon$ must be insignificant.
\end{proof}

\subsubsection{Hardcore bits from $k$-SUM and Zero $k$-Clique}
For both of these problems, planting a solution is exactly choosing some number of values ($k$ for $k$-SUM, and the edge weights of a $k$-clique for Zero $k$-Clique) and  changing one of them so that the values now give a solution.

\begin{corollary}
	Assuming either the Weak $k$-SUM hypothesis or weak Zero $k$-Clique hypothesis, there exist FGOWFs with fine-grained hardcore bits.
\end{corollary}
\begin{proof}
	This is straightforward due to the nature of planting for both of these hypotheses. Informally, planting for these problems is choosing a location within the given instance to put a solution. If an adversary learns where that solution is supposed to be, generating an instance without that specific solution is easy.
	
	First, let's prove this for $k$-SUM. The reason $k$-SUM is plantable is because $\Plant$ takes as its randomness $k$ indices in the $k$-SUM instance, and then changes the value one of them to make those $k$ instances form a solution the $k$-SUM. This randomness requires specifying $k$ instances out of $kn$, and an edge-weight. let $y$ be the $k\log(n)$ bits required to describe all $k$ locations that the planted solution lives; $y$ is part of the randomness in this case and we let $r$ denote which of these locations was changed. We can construct the following algorithm that inverts $\Plant(I; y, r)$ when given $y$.
	
	Let $\cB(I' = \Plant(I; y,r), y):$
	\begin{enumerate}
		\item Let $y[1] \in A_1$ denote the entry in list $A_1$ that is part of the $k$-SUM solution.
		\item Let $\hat I$ be $I'$ except with $y[0]$ changed to a different random value in the range $[0, R-1]$.
		\item Output $(\hat I; y, 1)$.
	\end{enumerate}

	$\cB$ runs in time $\tilde O(n)$, and is correct. The correctness comes from the fact that we preserve a zero-sum. $\Plant(\hat I; y, 1)$ will output an $I''$ such that $I''$ is just $\hat I$ with one entry changed, $y[1]$. $\hat I$ is the same as $I'$ but also with the same entry changed, $y[1]$. We need to show they are changed to the same value. In both $I''$ and $I'$, $\sum y[i] \equiv 0 \mod R$, and so $y[1] = \sum_{i=2}^k y[i] \mod R$. Because $y[2], \dots, y[k]$ are the same values across $I', \hat I,$ and $I''$, $y[1]$ is the same value in both $I'$ and $I''$. Finally, because we have a sub-polynomially sized advice to give an adversary for a $\PFT{n^k}$ adversary to produce a preimage, the fine-grained GL variant applies to the one-way function $\Plant$.
	
	The proof that Zero $k$-Clique has this property is analogous: planting chooses a specific location, describable in $\poly(\log(n))$ bits, to plant a clique. Knowing where the clique was planted allows one to quickly produce something in the preimage of a given instance.
\end{proof}.

%\xxx{Rio: To deal with at a later point. Maybe just some discussion.}
%\begin{claim}
%	Suppose $f$ is a medium or strong $\fgowf{T(n)}$ acting on $(x,y)$ where $x = n$ and $y = Q(n)$ for some subpolynomial $Q$, and let $b$ be a predicate on $(x,y)$ such that for all $\PFT{T(n)}$ adversaries $\cA$, $\Pr[\cA(f(x,y)) = b(x,y)] \le \frac 1 2 + \frac 1 {Q'(n)}$ for any subpolynomial $Q'$, then there exists a strong $\fgowf{T(n)}$ $f'$ with a strong hardcore bit $b'$.
%\end{claim}
%\begin{proof}
	%	This is just an application of the computational XOR lemma \cite{Vaz87} in combination with the techniques from claim \ref{thm:medium-strong-owf}.
	%	
	%	Recall the technique from claim \ref{thm:medium-strong-owf}: $f'$ consisted of concatenating $f$ together many times. How many times depends on whether or not $f'$ is easy to invert. If $\Pr[\cA(f(x)) \in f\inv(f(x))] = 1 - \frac 1 {\hat Q(n)}$ (so $f$ could be medium or strong since in both cases $\hat Q$ is sub-polynomial), then let $Q^*(n) = \max(Q'(n), \hat Q(n)) \cdot \log^2(n)$. Let $f' = f || \dots || f$, concatenated $Q^*(n)$ times. Then, $f'$ is definitely now a strong $\fgowf{T(n)}$, and also will have the following hardcore bit $b'$:
	%	\[b'((x_1, y_1) \dots, (x_{Q^*(n)}, y_{Q^*(n)})) = b(y_1) \xor \dots \xor b(y_{Q^*(n)}).\]
	%	
	%	Any $\PFT{T(n)}$ algorithm $\cA$ will be able to distinguish the vector $(b(y_1), \dots, b(y_{Q^*(n)})$
	%	\xxx{Rio: I'm having a very tough time figuring this out for whatever reason.}
	%TODO: figure this out
%\end{proof}
%%
%\paragraph{A note on fine-grained pseudorandom generators.}
%\xxx{Rio: I'm still looking into this. It's complicated...}
%TODO: constructions from GL and hc bits

%TODO: Hill construction? What about https://people.seas.harvard.edu/~salil/research/OWFtoPRG-stoc10.pdf

%\begin{definition}
%	A function $f$ is a nearly-weak $k,k'$-FGOWF if there exists a function $Q(n) \le O(n^{k-k'-\delta})$ for a constant $\delta > 0$ such that for all $\PFT{n^k}$ adversaries $\cA$,
%	\[ \Pr_{x \getsr \{0,\}^n}[ \cA(f(x)) \in f\inv(f(x)) ] \le 1 - \frac 1 {Q(n)}. \]
%\end{definition}
%
%\begin{claim}
%	Nearly-weak $k,k'$-FGOWFs imply strong $k$-FGOWFs.
%\end{claim}
%\begin{proof}
%	%TODO: it's gonna look like the previous proof
%\end{proof}
%
%%\remove{
%\xxx{There are some problems with these definitions. Need to work out where $\delta'$ comes in etc.}
%
%Just like in the usual cryptographic setting we have weak and strong OWFs (and weak OWFs imply strong OWFs), we have our own fine-grained version of weak and strong OWFs -- one will imply the other. There will be two versions: a `gap preserving' one-way function we will call a medium OWF, and an $\epsilon$-weak OWF.
%
%%TODO: there are some problems with these definitions...
%
%\paragraph{Definitions } 
%These functions will define the $\epsilon(n,\delta')$ to be different functions. In our first definition $\epsilon$ won't even depend on $\delta'$. It asks that the adversary have a sub-polynomial error in $n$.
%
%\begin{definition}[$d$-medium one-way functions]
%	A function $f: \{0,1\}^n \to \{0,1\}^*$ is $d$-medium one-way if $f(x)$ can be computed in $O(t(n))$ time and for all adversaries $\cA$ taking $O(t(n)^{g-\delta'})$ time for some $\delta'>0$, there exists a sub-polynomial function $
%	\epsilon(n)$ such that,
%	\[ \Pr_{x \gets \{0,1\}^n}\left[ \cA(f(x)) \in f\inv(x) \right] \le 1 - \frac 1 {\epsilon(n)} \]
%	%TODO: where does \delta' factor into this definition?
%	%%Andrea: I don't think it does. I think that we beleive that we can construct functions where, when \delta'>0 for any delta, the success is thus bounded. 
%\end{definition}
%
%In the above definition we force the adversary to err quite a bit. What about adversaries that err only $\frac{1}{\text{poly}(n)}$? Well, given that computing $f(n)$ takes $t(n)$ time and inverting $f(n)$ takes $t(n)^g$ time if the adversary errs, for example, $\frac{1}{t(n)^{g+1}}$ of the time, we could not detect this in $t(n)^g$ time. 
%
%But, the difference between inverting and solving gives us some space to work with, and in that space we can have certain amounts of error. 
%
%\begin{definition}
%	A function $f: \{0,1\}^n \to \{0,1\}^*$ is $(d,\epsilon)$-weak one-way if $f(x)$ can be computed in $O(t(n))$ time and for all adversaries $\cA$ taking $O(t(n)^{d-\delta'})$ time, there exists a function $g(n) = o(t(n)^{d-1-\epsilon})$ such that
%	\[ \Pr_{x \gets \{0,1\}^n}\left[ \cA(f(x)) \in f\inv(x) \right] \le 1 - \frac 1 {g(n)} \]
%\end{definition}
%
%\paragraph{Implications } 
%\begin{theorem}
%	The existence of a $d$-medium one-way function, $f$, implies the  existence of a $(d, n^{-c})$-one-way function, $f'$, for all constants $c$.
%\end{theorem}
%\begin{proof}
%	Let the probability of correct inversion of $f$ be upper bounded by $1-\frac 1 {g(n)}$. 
%	
%	We can draw $2cg(n)\lg(n)$  independent samples $x_1, \ldots , x_{2cg(n)\lg(n)}$ from $\{0,1\}^n$. Now, our new one way function is $f'(x_1|x_2| \ldots |x_{2cg(n)\lg(n)}) = f(x_1)||f(x_2)||\ldots||f(x_{2cg(n)\lg(n)})$. Correctly inverting the function $f'$ requires inverting $2cg(n)\lg(n)$ samples. The probability of correct inversion of this new function will be 
%	$(1-\frac 1 {g(n)})^{2g(n)\cdot c\lg(n)} < $
%	
%\end{proof}
%
%\begin{theorem}
%	The existence of a $(d,\epsilon)$-weak one-way function implies the  existence of a $(d/(d-\epsilon), n^{-c})$-one-way function for all constants $c$.
%\end{theorem}
%\begin{proof}
%	
%	\xxx{We build this proof by doing many repetitions of the medium one way functions. Repeating the function $cg(n)\lg(n)$ times achieves this while preserving the polynomial gap.}
%\end{proof}

%\xxx{Rio: removed explicit discussion about explicit $k$-SUM construction}
%\subsection{One Way Functions}

%\begin{theorem}
%If an problem is hypothesized to take  $\tilde{\Omega}(t(n)^{1+\delta})$ time for some $\delta>0$ time to find a solution with probability $\geq 1/3$  and is plantable in $t(n)$ time with error $< 2/3$ then a fine grained one way function exists. 
%\end{theorem}
%\begin{proof}
%	\xxx{TODO: but you know, its not so hard to prove this}
%\end{proof}

%Given $I,(a,b,c)$ and, $(w_{a,b}, w_{b,c})$ let $I'$ be an instance of $I$ with three edge weights changed. Specifically, set $w(e_{a,b})= w_{a,b}$, $w(e_{b,c})= w_{b,c}$ and, $w(e_{c,a})= -w_{a,b}-w_{b,c}$.
%
%\begin{definition}
%Let $I$ be an instance of $0$ k-clique
%Let $f_{kClique}$ be the function 
%$$f_{kClique}(I,(a,b,c),(w_{a,b}, w_{b,c})) =
%\begin{cases}
%\emptyset , & \text{if }e(a,b), e(b,c),\text{or } e(c,a) \text{ are involved in a }0 \text{-triangle in I} \\
%\emptyset , & \text{if }e(a,b), e(b,c),\text{or } e(c,a) \text{ are involved in }> \text{1  }0 \text{-triangles in I'} \\
%I', & \text{else}
%\end{cases}
%$$
%\end{definition}
%
%\xxx{TODO: can we get away with not checking for the null characters? It will still be hard over the distribution when the inputs are average case 0 solutions. Then computing $f$ will be $O(n^2)$ this doesn't matter unless $k>4$.}
%
%\begin{theorem}
%The function $f_{kClique}$ is a fine-grained one way function over the distribution of inputs drawn uniformly from $k$-Clique instances with $0$ solutions given the average case $0$-k Clique assumption. 
%\label{thm:kcliqueOWF}
%\end{theorem}
%\begin{proof}
%Computing $f_{kClique}$ takes $n^{k-2}$ time when the instance $I$ has $n$ nodes. 
%
%Let $D_I$ be the uniform distribution over $0$-k clique instances with $0$ solutions. \\
%Let $D_{a,b,c)}$ be the uniform distribution of triples with each value chosen uniformly from $[1,n]$.\\
%Let $D_{w}$ be the distribution from Lemma \ref{lem:kcliquePlant} that generates average case solutions. \\
%Let $D_{in}$ be the distribution made by sampling $I$ from $D_I$, $(a,b,c)$ from $D_{(a,b,c)}$ and $(w_{a,b},\ldots)$ from $D_{w}$.
%
%Let the Adversary have a $\epsilon$ probability of inverting the function when the input to the function is chosen from $D_{in}$.
%
%We will then use the adversary to distinguish a random $0$ solution instance from a $1$ solution instance. If we are given an instance $\hat{I}$ then we give the adversary this instance and ask for an inversion. 
%
%If the instance has $0$ solutions the adversary will be unable to invert (no $(a,b,c)$ triple will form a $0$-triangle). If the instance has $1$ solution, this is by Lemma \ref{lem:kcliquePlant} going to be the same distribution as applying the function to the distribution from $D_{in}$. 
%
%Thus, the Adversary will invert the function and find the $0$-k clique an $\epsilon$ fraction of the time. If the Adversary fails we will guess $0$ solutions, if the Adversary succeeds we will guess $1$ solution. 
%
%Given that  $\hat{I}$ has a $1/2$ chance of being a $0$ input then we guess correctly $1/2+\epsilon$ of the time. 
%
%Thus, the Adversary can not invert the function correctly with probability $\geq 1/3$.
%\end{proof}